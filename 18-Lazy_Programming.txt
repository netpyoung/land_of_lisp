LAZY PROGRAMMING
18장.lazy 프로그래밍

 14장에서, 여러분은 프로그램이 순수하며 수학과로-같은 함수로 만들어 질때 단순하고 깔끔해 질 수 있다는 것을 배웠습니다. 이러한 함수들은 오로지 인자에 기반하여 항상 동일한 결과를 반환합니다. 이러한 함수들에 의존한다면, 여러분은 함수형 프로그래밍 스타일을 이용하는 것입니다.

 그러나, 15장에서 Dice of Doom게임을 만들기 위해 함수형 프로그래밍 스타일을 이용하였을때, 문제가 명백히 드러났습니다: 함수가 인자에 전적으로 기반하면, 이에 통과시켜야 하는 게 비대해진다는 것입니다.

 Dice of Doom게임에서, 저희는 게임 보드의 모든 가능한 미래 상태를 지닌 game-tree 변수를 전달했습니다. 쥐꼬리만한 3x3 보드라 할지라도, 이는 실제로 거대한 구조입니다! 따라서 게임의 현재 디자인은 여러분의 코드를 매우 단순하고 우아하게 만드는 반면, 기하급수 적으로 커지는 게임 트리를 갖는 거대한 게임 보드의 크기를 잘 조정하는 것처럼 보이진 않습니다. 저희가 생각할 수 있는 우아한 코드를 유지하며 큰 보드에서의 더욱 복잡한 게임을 허용하는 하나의 방법은, 게임 시작부분에서 모든 가능성있는 move를 곧바로 보지 않도록 저희 프로그램을 충분히 영리하게 만드는 것입니다. 이것이 가능할까요? 물론, 이는 lazy evaluation 기법을 이용하면 가능합니다. 이번 장에서, 저희는 향상된 Dice of Doom을 만들기 위해 lazy evaluation을 사용할 것입니다


Adding Lazy Evaluation to Lisp
 lazy evaluation로, 저희는 여전히 저희 코드의 한 지점에서 전체 게임 트리를 만들 수 있습니다 - 게임 시작 부분에서. 그러나, 저희는 기발한 트릭을 이용하여, 게임 트리의 가지를 구름속으로 숨겼습니다:
[pic]

 게임 트리 가지는 여전히 시작부분에서 바로 선언되었습니다. 그러나, 저희는 구름속에 있는 가지들에 대한 계산을 수행하는데 애쓰지는 않고, 대신 저희는 "실제" 가지를 만들때 이를 수행합니다. 이것이 lazy evaluation의 lazy part 입니다.

 대신에, 저희는 누군가가 구름낀 가지를 "살펴"보는지를 기다립니다. 이게 일어나는 순간, 팟!하고, 그 지점에 실제 게임 트리의 가지를 생성합니다:
[pic]

 이는 게임 트리에 있는 가지가, 코드의 어떤 부분이 이를 살펴보는 경우에만, 생성된다는 것을 의미합니다. 플레이어가 게임에서 특정 move를 선택하지 않는다면, AI는 이에 대항하기 위한 결정을 내리지 않을 것이며, 저희 프로그램은 게의르게도 주어진 가지가 실제로 어떻게 보여지는지 밝혀내는데 필요한 계산을 하지 않을 것입니다.

 Haskell과 Closure Lisp와 같은 언어는, 언어의 핵심 부분으로 lazy evaluation을 지원합니다. 사실, Closure는 이의 사용을 독려하며, 함수형 프로그래밍에 있어 이게 얼마나 유용한지를 명백히 보여줍니다. 그러나, ANSI Common Lisp 표준은 lazy evaluation와 유사한 어떠한 기법도 포함하지 않습니다. 다행스럽게도, Common Lisp의 강력한 매크로 시스템으로, 저희는 쉽게 저희 스스로 이러한 기법을 언어에 추가할 수 있습니다!


Creating the lazy and force Commands
 저희가 만들 lazy evalution을 위한 가장 기본적인 명령어는 lazy와 force입니다. lazy 명령어는 코드 조각을 둘러쌀 수 있게 하며, Lisp에게 이처럼 게의른 방식으로 코드가 평가되길 원한다고 말하는 wrapper가 될 것입니다:
[REPL]

 보시다시피, 컴퓨터는 1 더하기 2의 값을 계산하려 하지 않습니다. 대신, 이는 단순히 함수를 반환합니다. 실제 계산 결과를 얻기 위해선, lazy 값에서 다른 기본 lazy evalution 명령어를 호출해야합니다:
[REPL]

 중요한 것은 lazy 값이 생성됬을 때가 아니라, force됬을때 계산이 수행됬다는 것입니다. 이 상황를 이해하기 위해, 더욱 복잡한 예제를 살펴 봅시다:
[REPL]

 여기, 저희가 만든 덧셈이 일어나면 부수 효과로 콘솔에 메시지를 출려하는 add 함수가 있습니다. 다음으로, 게의르게 함수로 두 숫자를 더하고 결과를 변수 *foo*에 저장합니다. 그리고 나면, "I am adding now"라는 메시지가 보이지 않기에, 저희는 덧셈이 실제로 발생하지 않았다는 것을 알게됩니다.

 그 다음으로 저희는 변수를 force합니다. 변수를 force하면, 계산이 실제로 수행되며, 3이란 결과가 반환됩니다. 저희는 lazy 값을 force하여, 메시지가 콘솔에서 출력되었을때 덧셈이 발생한다는 것을 알 수 있습니다.

 여기 lazy의 간단한 구현 코드가 있습니다:
[source]

 저희는 매크로를 선언하여 lazy를 구현하였습니다. 매크로는 이가 생성할 코드에 있어 두 변수가 필요합니다. 이를 16장에서 다룬 gensym 이름으로 선언해야 합니다. 다음으로, 매크로가 출력할 코드를 생성하기 시작할 것입니다 (이번 라인의 시작부근의 역따옴표를 주목하기 바랍니다).

 매크로에 의해 생성된코드 상단 부분에 있는 것이, 저희가 생성한 gensym 이름을 이용하여 두 지역 변수를 선언한 것입니다. 첫번째 변수는 이 lazy 값이 force되었는지 말해줍니다. 이게 nil이라면, 값은 구름속으로 숨을 수 있습니다. 이 변수가 true라면, 값은 force되었기에 더이상 구름속에 숨을 수 없습니다.

 일단 이 값이 force 호출로 계산되면, 초기의 이 값이 사용되지 않고 nil로 설정되었더라도, 결과 값을 다른 변수로 저장합니다. lazy 매크로가 호출될때, 저희는 이것이 결과를 반환하는 lazy 값을 force하기 위해 나중에 호출될 수 있는 함수를 반환하기를 원합니다. 그러므로, lambda 함수를 다음에 선언합니다.

 이 lambda 함수 외부에 선언된 지역 변수라도 closure란 함수에 의해 capture될 수 있다는 것을 명심하시기 바랍니다. 이는 3, 4번째 위에 있는 지역 변수는 이후 lambda 함수의 호출 간에 지속된다는 것을 의미합니다. 왜 이것이 문제가 될까요? 흠, 일단 구름이 팟!하게되면, 값을 계산하는 모든 작업을 완료할 것이며, 저희는 나중에 다시 lazy 값이 force되고 check될때 이가 또다시 수행되는 것을 원치않습니다. 호출 간에, 이곳(_4_)에 처음 force한 값을 기억함으로써 이를 피할 수 있습니다.

 (저희가 만든 lambda 함수를 호출함으로써) lazy 값이 force되면,
저희가 스스로 답할 처음 질문은 이것이 이미 force되었는지 여전히 구름뒤에 가려졌는지입니다. 아직 force되지 않은 값에 대해, 팟!해서 lazy 계산을 수행하고, 이를 값으로 저장합니다. 이를 force되었다고 표시합니다. 이제 구름이 사라졌습니다.

 일단 구름이 사라지면, 저희는 단순히 계산된 값을 반환할 수 있습니다. 이는 방금just 계산되었거나, 이전 호출에 의해 이미 존재할지도 모릅니다.

 (인정컨데 정신을-혼란스럽게하는) lazy 매크로 코드와는 달리, force 함수는 엄청-단순합니다. 이것이 하는 일은 lazy에 의해 생성된 lambda 함수를 호출하는 것 뿐입니다: 
[source]

 저희는 이제 많은 다양한 종류의 정교한 도구들을 이 단순한 lazy와 force 명령어를 기반으로 하여 만들 수 있습니다.


Creating a Lazy Lists Library
 이제 저희는 Clojure 구현에 느슨lossely하게 기반을둔 lazy list 라이브러리를 만들기 위해, 새로운 명령어를 이용할것입니다. (Clojure에서, lazy list는 lazy sequnce로써 참조됩니다.)

 Lisp 리스트에 동작하는 함수형 명령어는 cons 명령어이기에, lazy 리스트를 처리하기 위해 저희가 만든 처음 명령어가 lazy-cons 명령어란 것이 별로 놀랄만한 일은 아닙니다:
[source]

 결과가 lazy 매크로속에서 wrap된다는 것을 제외하면, 이 매크로는 cons의 행동을 따라합니다. lazy-cons를 수행하기 위해선, lazy-car와 lazy-cdr 명령어 또한 만들어야 합니다:
[source]

 이러한 함수가 하는 일은 lazy 값을 force하고 각각 car와 cdr을 호출하는 것입니다. 이 새로운 명령어를 이용해 봅시다:
[REPL]

 보시다시피, 마치 cons를 이용한 것처럼 lazy-cons를 사용할 수 있습니다. 그리고, cons를 분리한 것과 동일한 방식으로 lazy cons를 분리할 수 있습니다.

 더욱이, lazy 리스트 함수는 표준 cons, car, cdr 함수와 다를바 없는 것처럼 보입니다. 그러나, 저희는 실제로 이를 이용하여 매우 놀랄만한 일을 수행할 수 있습니다. 예를들어, 다음 정의를 고려해봅시다:
[source]

 여기서, 저희는 불가능한 무언가를 선언하기 위해 lazy-cons 명령어를 사용했습니다:
모든 양의 정수를 담는 변수! 지역 함수 f를 생성하고, 영원히-증가하는 숫자 n을 이용하여 무한한 lazy-cons의 사슬을 만들기 위해 이를 재귀적으로 호출함으로써 이를 수행합니다. 일단 이처럼 보기에 불가능한 *integers* 변수를 선언하면, 여러분이 예상하는 것처럼 이를 이용할 수 있습니다:
[REPL]

 lazy- 명령어를 사용하는 동안, 필요한 만큼 *integers*에 있는 더욱 더 많은 숫자들을 force함으로써, 저희는 무한한 정수 리스트로부터 무엇이든지 간에 꺼내올 수 있습니다.
 
 (양의 정수 list 처럼) 모든 리스트가 무한이 되는것은 아니기에, 리스트를 종결시키기 위해 또한 lazy-nil의 개념이 필요합니다. 정규 list의 끝을 확인하는데 사용하는 null 함수와 유사하게, 리스트에 끝에 도달했는지 확인하는데 사용할 수 있는 lazy-null 함수를 필요로 합니다.
[source]

 저희는 이제 lazy list를 가지고 작업할 모든 기본 빌딩 블록들을 가졌으며, 라이브러리를 위한 몇몇 유용한 함수를 만들어 봅시다.


Converting Between Regular Lists and Lazy Lists
  저희가 하고자 하는 것중 명백한 것 하나는 정규 리스트를 lazy 리스트로 변환시키기 원한다는 것입니다. make-lazy 함수른 이러한 일을 허용케 합니다:
[source]

 make-lazy 함수가 깔끔하게 보여준 것처럼, lazy 리스트 라이브러리 함수를 작성하는 것은 zen koans이 작성한 것처럼 짧습니다. 이를 이해하는 유일한 방법은 이를 오랫동안 살펴보는 것입니다. 영어는 make-lazy와 같은 함수를 명백히 설명해낼 적합한 단어를 가지고 있지 않습니다

 간단히 말하자면, make-lazy는 리스트를 탐색하기 위해 재귀를 이용하며, lazy 매크로의 호출에서 각 cons를 wrap합니다. 그러나 이 함수 (그리고 lazy 라이브러리에 남아있는 다른 함수들)의 진정한 의미를 얻기 위해선, lazy와 force가 실제로 무얼 의미하는지 주의깊게 생각하며, 각 함수에 대해 다소 생각해봐야 합니다. 다행스럽게도, lazy 리스트 라이브러리가 완성되면, lazy evaluation의 상당수의 이상한 부분이 감춰질 것입니다.

 regular 리스트를 lazy 리스트로 변환하는 make-lazy 함수를 작성한 것처럼, 역으로 수행하는 함수를 만들 수 있습니다 - lazy 리스트를 regular로 전환시키는. take와 take-all 함수는 이를 허용케 합니다.
[source]

 lazy에서 regular 리스트로 가기 위해 두개의 서로다른 명령어가 필요한 이유로는, regular 리스트와는 달리, lazy 리스트는 무한하게 늘어날 수 있기 때문입니다. 그러므로, 리스트에서 특정 항목의 갯수를 얻어 내는 추가 명령어를 갖는 것이 유용합니다. take 함수는 저희가 취하기 원하는 값의 수를 나타내는 추가 인자 n을 받습니다. 모든 값들을 원한다면, take-all 함수를 호출 할 수 있습니다. 물론, 이 함수는 무한 리스트에 사용할 수 없습니다 - 무한 리스트로부터 모든 항목을 취하는 것은 무한 루프를 야기하기 때문입니다.

 새로운 lazy 리스트 변환 함수를 테스트 해봅시다:
[REPL]

 예상한 대로, 모든 양의 정수 리스트로부터 처음 10개의 정수를 취한다면, 1부터 10까지의 수를 결과로 얻을 것입니다. take 함수는 make-lazy 를 호출하여 만든 유한한 리스트에서도 이용할 수 있습니다. 그러나 리스트가 유한하면, 더 단순한 take-all 함수를 이용하여 lazy 리스트에서 regular 리스트의 모든 항목을 얻을 수 있습니다.


Mapping and Searching Across Lazy Lists
 저희는 또한 lazy 리스트에 대해 map과 seach가 가능하길 원합니다. 여기 이를 허용케하는 몇몇 함수들이 있습니다:
[source]

 이 함수들은 함수 mapcar, mapcan, find-if, nth와 유사합니다. 유일한 차이점은 lazy리스트를 받고 반환한다는 것입니다. 이는 nul, car, cdr을 이용하는 대신, 방금 만든 이러한 함수들의 lazy 버전(lazy-null, lazy-car, lazy-cdr)을 이용한다는 것입니다.

 이 함수들을 이용하는 것은 매우 쉽습니다:
[REPL]

 양의 정수에 대해 2루트함수를 map하기 위해 laz-mapcar를 호출하여 저희에게  2루트된 양의 정수의 lazy 리스트를 줍니다. 처음 10개가 보여졌습니다. 다음으로, lazy-mapcan을 호출하고 각 양의 정수가 짝수인지 확인합니다. 그렇다면, 수의 lazy 리스트를 반환합니다. 그렇지 않다면, 빈 lazy 리스트를 반환합니다. 결과는 모든 짝수가 걸러진 정수 lazy 리스트입니다. lazy 리스트에 있는 첫번째 홀수를 찾기 위해 lazy-find-if 를 이용할 수 있습니다. 이러한 경우, 수는 7입니다. 마지막으로, lazy 리스트의 특정 지점에 있는 수를 얻기 위해 lazy-nth를 이용할 수 있습니다.

 단순하긴 하지만, 이제 저희는 lazy 리스트 라이브러리를 다 작성했습니다.

 이제까지 이번 장에서 작성한 모든 함수들을 lazy.lisp란 파일에 넣습니다 (혹은 단순히 http://landoflisp.com/에서 그 파일을 다운 받습니다).

 이제, 여러분은 이 lazy 리스트가 Dice of Doom게임 엔진의 힘을 상당하게 키워주는걸 보게될 것입니다!


Dice of Doom, Version 2
 15장에서, 저희는 Dice of Doom 게임의 첫번째 버전을 만들었습니다. 저희는 이제 그 버전에서 몇몇 함수를 수정할 것입니다. 이를 진행하기 위해  그 장의 코드를 dice_of_doom_v1.lisp 파일로 넣음으로써,
새로운 버전에서 이를 참조할 수 있습니다 (혹은 http://landoflisp.com/에서 그 파일을 다운 받습니다).

 Dice of Doom의 이전 버전과 새로운 lazy 리스트 라이브러리를 사용하기 위해, REPL에서 다음을 돌려봅시다:
[REPL]

 다음, 보드의 크기를 더 큰 4x4 로 늘릴 것입니다:
[REPL]

 이러한 보다 큰 크기에서 괜찮은 속도로 게임을 돌리기위해, 게임 트리의 각 가지에서의 moves 리스트를 regular 리스트 대신 lazy 리스트로 만들 것입니다. 단순히 저희 게임에서 이러한 구조를 regular 리스트를 lazy 리스트로 변환시킴으로,
전체 게임 트리는 결과적으로 lazy가 됩니다. 이를 수행하기 위해, 저희는 이제 저희 게임의 첫번째 버전의 몇몇 함수를 새로운 list 함수를 이용하는 걸로 재정의를 해야합니다.

 우선, 주어진 보드 위치에서 가능한 공격attack과 넘김pass을 계산하는 함수에 자그마한 수정을 가해봅시다:
[source]

 보시다시피, add-passing-move 함수는 단 하나의 자그마한 변화만을 필요로 합니다. moves의 리스트가 이제 lazy 리스트임으로, passing move를  move가 가능한 리스트의 상단에 더하기 위해 lazy-cons를 이용합니다.

 attacking-moves 함수는 좀 더 많은 변화를 요구합니다. 우선, 이는 이제 lazy 리스트를 반환해야 하므로, 저희는 moves를 계산하는 동안 두 장소에서 mapcan 대신 lazy-mapcan을 이용합니다. lazy-mapcan 함수는 또한 make-lazy 함수의 수행으로 이 내부가 lazy인 리스트를 요구합니다. 또한, 저희가 nil을 반환했던 장소에선 대신 이젠 lazy-nil을 반환합니다. 마지막으로, 계산된 보드 위치의 리스트가 외부 lazy-mapcan에 반영되므로, 이를 lazy로 만듭니다

 다음으로, 인간 플레이어를 다루는 두 함수에 동일한 변화를 줍시다:
[source]

 handle-human 함수에서, moves의 리스트에 대해 list-eater 함수인 지역 함수 print-moves를 가졌습니다. 이를 리스트의 끝을 검사하고, 리스트의 앞 부분을 잘라내고, 리스트의 꼬리를 따라 재귀할때 lazy 명령을 사용하도록 수정할 것입니다. 마지막으로, handle-human이 인간이 옵션 리스트에서 move를 선택한 후에 move 를 집도록, lazy-nth 를 이용하도록 수정할 것입니다.
 
 play-vs-human 함수에, 아주 작은 변화를 줄것입니다. 게임에 끝에 도달했는지 판별하기 위해, 가능한 moves의 subsequent 리스트가 비어있는지 확인하고, 승자를 알립니다. moves의 lazy 리스트가 비어있는지 확인하기 위해 저희는 단순히 lazy-null을 이용합니다.

 이러한 단순한 변화로, 플레이어가 이를 만들기로 결정하지 않는한 트리의 어떠한 move도 실현되지않기에, 더욱 큰 보드 크기에서 인간에 대항하는 Dice of Doom을 플레이 할 수 있습니다. 커다란 4x4 보드에서, 게임(바로 버전 1의 게임)을 진행하기 위해 다음 것을 입력합니다:
[REPL]

 이 명령어가 실행된다면, 버전 1은 끽하고 움직임을 멈출 것입니다. 이는 게임이 시작되기 전에, 전체 게임의 모든 가능한 moves에 대한 전체 게임 트리를 생성하기 때문입니다.

 lazy 버전의 Dice of Doom에선 게임이 곧 바로 실행됩니다!


Making Our AI Work on Larger Game Boards
 다음으로, moves진행할때 새로운 lazy 리스트 라이브러리를 사용하도록 AI 함수를 조정할 것입니다. 그러하면서, 저희는 AI 코드에대한 몇몇 추가 구현을 만들것입니다.


Trimming the Game Tree
[pic]

 버전 1의 Dice of Doom에서, 저희 AI 코드는 어떤 방식에선 굉장히 강력합니다. 이는 매 결정마다, AI 플레이어는 절대적으로 최선인 다음 move를 고르기 위해 미래에 가능한 모든 보드 위치 살펴보기 때문입니다. 이러한 방식에선, 이길 수 있는 모든 게임에서 이기는 완벽한 Dice of Doom 게임이 가능합니다.

 그러나, 이와 같은 디자인은 커다란 보드와는 맞지 않습니다. 미래에 가능한 move들이 너무 많아서 한번에 생각하기 불가능하기 때문입니다. 사실, lazy 게임 트리의 요점은 모든 가능한 move에 대해 생각하지 않는 것입니다. 그러므로, 컴퓨터에게 "여기까지 move만 고려하고, 더이상은 하지 말아라." 라고 말할 방법이 필요합니다. 다시 말하자면, 저희는 앞선 2, 3, 4 moves만 살펴보라고 말할 수 있길 원하며 나중 것들을 살펴보지 않습니다.

 Dice of Doom 의 함수형 프로그래밍 스타일은 저희에게 매우 우아하지만 불확실한 방식을 선사합니다.

 문제의 확실한 해결책은 version 1의 get-ratings와 rate-position을 새로운 인자 search-depth를 지니도록 수정하는 것입니다. 그런 다음 이러한 함수들의 호출에서 "우리가 원하는 최대 depth에 도달했는가?"라고 스스로 묻습니다.

 이러한 접근법의 문제는 추가적이며 혼란스런 코드로 함수를 더럽힙니다. 사실, 보드 위치를 평가하는 방식은 우리가 찾기 원하는게 얼마나 깊은지와 이론적으로 별개의 이슈입니다. 프로그래머들이 말하길, 이러한 이슈는 orthogonal이며, 이러한 이슈들을 독립적으로 다룰 수 있다면 best가 될거라 합니다.

 사실, lazy 게임 트리에서, "trimming" 탐색 트리에 홀로 반응하며, 가능한 moves를 생각하고 rate하는 주 AI 코드로부터 완전히 독립적인 개별 함수를 작성하는 것이 가능합니다.

 여기 저희 트리를 trim하는 함수가 있습니다:
[source]

 이는 두개의 인자를 취하는 매우 간단한 함수입니다 : lazy 트리와 trim하기 원하는 깊이. 결과적으로, 이는 재귀적으로 자기 자신을 호출하여, 각 레벨의 depth를 줄여가며 트리를 탐색함으로 새로운 게임 트리를 내놓습니다. 이 깊이가 0에 도달하면, trim하기 원하는 레벨에 왔다는 것을 알게되며 moves의 lazy 리스트를 빈 리스트로 설정합니다.

 이제 저희가 원하는 것은 AI rating 계산을 하기 전에 새로운 limit-tree-depth 함수를 호출하는 것입니다. 이러한 것을 handle-computer 함수를 조금 고침으로 행합니다:
[source]

 다음에 가능한 move의 rating을 얻기 위해 get-ratings을 호출하기 전에,
게임 트리를 trimmed 게임 트리로 변형시킵니다. 이제 저희 AI 코드는, 커다란 게임 트리가 존재하거나 이 계산에 포함되지 않은 더 깊이 있는 moves가 있다는 사실을 완전히 알지 못한체, trim된 트리에서 돌아갑니다. 이러한 기법으로, 실제 보드 위치를 평가하는 알고리즘에서 AI search deapth를 제한하는 코드를 분리시켰습니다. 또 다른 자그마한 수정은 moves의 lazy 리스트에서 move를 꺼내올 때 lazy-nth를 사용한 것입니다.

NOTE
 limit-tree-depth 함수는 트리를 trimming 하기위해 매우 대충만든 방법을 이용하였습니다 : 모든 트리 가지를 단순히 특정 depth 이하로 trim합니다. 대다수의 보드 게임에서, 이는 게임 트리를 trimming 하는 최상의 방법입니다. 그러나, Dice of Doom은 각 플레이어에게 row에 있는 다수의 moves이 허용되는 일반적이지 않은 특성을 지녔습니다. limit-tree-depth가 trimming 가지의 기준치로써 얼마나 많이 바꾸느냐를 고려한다면 더 좋은 최선책이 될 것입니다. 그러나 단순한 버전도 충분히 잘 동작합니다.

 이 시점에서, 또한 play-vs-computer에 정확한pinpoint 변화를 줄 수 있습니다:
[source]

 여기선, 하나의 지점에서 moves의 lazy 리스트의 끝을 검사하기 위해 lazy-null을 추가하기만 하였습니다.

 이제 AI 코드의 힘을 증가시켜줄 또다른 꼼수를 살펴봅시다


Applying Heuristics
 게임 트리를 trimming 함으로써 저희 AI 플레이어를 근본적으로 바꾸었습니다. trimming 없이 AI 플레이어는 항상 완벽한 게임이 가능합니다. 그러나, trimming 트리로, 더이상 미래에 가능한 모든 move를 생각하지 못하기에 AI가 "무언가를 잊어버리는것"이 가능합니다. Dice of Doom version 2에서 컴퓨터 플레이어는 더이상 완벽한 게임이 가능하지 않을까요? "꽤 좋은" 게임은 가능합니다.

 기본적으로, 저희는 더 좋은 성능을 위해 완벽한 게임을 플레이 하는 AI의 능력을 맞바꾸었습니다. 진행하면서, AI 코드를 수학적으로 분석될 수 있는 어떤 정밀한것에서 "흐믈흐믈"하며 정확성과는 거리가 먼 무언가로 바꾸었습니다.

 컴퓨터 과학에서 말하는 것처럼, 저희는 이제 휴리스틱스의 세계로 들어섰습니다. 컴퓨터 과학에서, 휴리스틱스heuristics는 완벽하지 않지만 매우 빠르게 좋은 결과를 엎게 해주는 프로그래밍 기법입니다. 대게 말하자면, 빠르지만 100 퍼센트 동작하는 것을 보증하지 않는 어떠한 기법은 휴리스틱스입니다. (지금 Dice of Doom AI 엔진이 행한것처럼)heuristics을 이용하는 코드를 작성하거나 어떠한 창조적인 생각을 이용하고 다양한 방식으로 코드를 "가지고놀때" 이는 종종 가치있습니다

 기본적으로, 이미 완벽한 해결책을 포기하였고 부정확한 기술을 이용하기에, 휴리스틱스 코드에 대한 손잡이knobs에 대해  결과를 극적으로 향상시킬수 있는 다양한different 방식으로 수정이 가능합니다. 그리고 실로, AI 플레이어의 게임을 극적으로 향상시키는, Dice of Doom AI 휴리스틱스를 만들 수 있는 단순한 변화가 있다는 것이 판명되었습니다.


Winning by a Lot vs. Winning by a Little
 Dice of Doom 코드 version 1에서, AI 플레이어는 승리의 가능성에 대해 어떠한 걱정을 할 이유가 없었습니다. 게임이 끝나면, 이는 적보다 적어도 하나 더 많은 보드 영토를 점령하는 데에만 신경을 쓸 것이며, 이는 승리를 의미합니다.

 그러나, 이제 AI 코드에서 부정확한 휴리스틱스를 이용하므로, 게임에서 어떠한 지점에 있는 the lead가 얼마나 많고 큰지가 문제됩니다. 이 상황을 위한 휴리스틱스 규칙은 " 앞서 살펴볼 수 있는 move가 매우 적을지라도, 게임에서 적을 완벽히 굴복시킨다면, 그/그녀는 회복하기 매우 힘들 것이다."라는 것입니다.

 (AI에서 사용했던) minimax 알고리즘은 트리의 모든 마지막 leaf 가지를 위해
point score를 할당합니다. 저희 게임 version 1에선, 이 score는 0이나 1, 혹은 때때로 게임이 비길때에는 1/2입니다. version 2에선, 이는 실제로 게임에서의 "마지막 leaves"가 아니며, 더욱 작아진 trimmed 트리에서의 단순한 leaves입니다. 이러한 상황에서, leaf point score가 큰 값의 범위를 가진다면 훨씬 좋으며, 어떤 moves가 "많은 것"에 인도lead하는지, "적은 것"에 인도lead하는 지를 말할 수 있습니다.

 leaf에서 보드 위치를 score하기 위해 더욱 복잡한 휴리스틱스를 이용하는 score-board 함수를 작성해 봅시다:
[source]

 score-board 함수는 보드의 모든 6각형을 loop하고, loop 매크로의 sum directive를 이용하여 loop하고 각 6각형의 point의 총합을 만듭니다. 저희가 scoring하는 플레이어가 현재 6각형을 소유한다면, 총합에 point를 더할 것입니다.

 총합에 얼마나 많은 point가 더해졌는지를 정확히 하기 위해, 또다른 휴리스틱스 관측을 만들었습니다. : 강력한 적에 이웃된 6각형들은 강력한 이웃이 없는 6각형보다 매우 가치있습니다. 저희는, 적과 이웃한 6각형을, 위협threatened받은 6각형에 있던 보다, 더 많은 주사위를 가졌다고 여길것입니다. 위협받는 6각형에 대해선, point 총합에 단지 1 point만 더할 것입니다. 위협받지 않은 6각형에 대해선, 2 point를 더할 것입니다. 마지막으로, 상대 플레이어에 의해 점령당한 각 6각형에 대해, 총합에서 1포인트씩 뺄 것입니다.

 다시말하건데, 구현하는데 있어 중요한 것은 score-board가 휴리스틱스 함수라는 것이며, 그와 같은 score를 생성하는데 있어 진실로 옳거나 나쁜 방법이 없습니다. 위협받지 안은 6각형에 대해 2 point를 더하는 대신에, 쉽게 1.5 point를 더할 수 있습니다. 이번 예제를 만들면서, 다양한 score-board 함수의 버전을 이용하여 다양한 적들과 예행 플레이를 해봤으며, 이 버전이 적당히 동작한다고 결론지었습니다. 휴리스틱스를 발생하는 것은 정확한 과학이 아닙니다.

 여기 주어진 6각형이 위협받는지를 결정하는 함수가 있습니다:
[source]

 우선, 질문으로 6각형을 얻고 점령한 플레이어가 누구인지, 플레이어가 얼마나 많은 주사위를 가지고 있는지 밝혀냅니다. 그런 다음 현재 위치에서 인접한 모든 사각형을 loop합니다. 그런 다음, 플레이어와 각각 이웃의 주사위 갯수를 찾아냅니다. (이웃을 위협하는) 더 큰 주사위 갯수를 지닌 적이 점령한 인접 6각형을 발견하자마자, true를 반환합니다. 이러한 방식으로 반환을 호출하는 것은, true를 결과로 하여 loop를 쉽게 멈추도록 합니다.

 이제 저희는 score-board와 threatened 함수를 완성하였고, 향상된 get-rating과 rate-position함수를 작성할 준비가 되었습니다:
[source]

 보시다시피, 저희는 몇몇 코드 라인을 새로운 lazy 게임 트리와 호환가능하게 업데이트하였습니다. 다음에 오는 move가 없는 게임 위치는 이제 새로운 score-board 함수가 호출되도록 할 것입니다.

 이제 저희는, 커다란 게임 보드에서 플레이가 가능한 완벽하게 동작하는 휴리스틱스 AI 플레이어를 가졌으며, 이를 시험해 봅시다. 늘 그렇듯이, 다음 예제에 있는 플레이어 B의 모든 움직임은 AI 알고리즘에 의해 자동적으로 계산되어집니다:
[REPL]

 이 바뀐 시점에서, AI 플레이어는 무작위로 moves를 고르는 플레이어에 대해 이기는 게임은 대략 65에서 70 퍼센트일 것입니다. 이는 실제로 좋은 결과입니다. 간단한 gen-board 함수는 종종 매우 편향된 시작 지점을 생성하므로, 컴퓨터는 남아있는 30 퍼센트의 게임들을 간단하게 이길수 없을 것입니다.


Alpha Beta Pruning
 Dice of Doom version 2의 AI를 향상시킬 마지막 하나를 추가해봅시다.

 Alpha-beta 가지치기pruning는, 마지막 minimax 평가가 영항이 미치지 않는다는게 확실하다면 몇몇 가지를 건너띔으로 성능을 향상시키는 잘 알려진 minimax 알고리즘의 최적화입니다.
[pic]

 게임 트리의 가지가 최종 결과에 영향을 미치지 못하는건 언제일까요? alpha-beta 가지치기가 어떻게 동작하는지 이해하기 위해, 2x2 보드의 단순한  게임트리를 보여주는 다음 그림을 살펴봅시다
[pic]

 그림의 상단이 게임 시작 위치입니다. 화살표는 moves가 가능한 것을 가리킵니다. 각 보드 위에 있는 것은 현제 어떤 플레이어(A나 B)가 move를 하는지를 나타냅니다.

 이 그림은 또한 게임트리의 minimax 분석의 결과를 보여줍니다. 각 보드의 오른쪽 하단에서, 여러분은  (새로운 score-board 로직과 함께)최신 get-ratings 함수가 어떻게 위치를 rate하는지 보여주는 숫자를 확인할 수 있습니다. (보드의 가장 아레에 있는) leaf nodes에 대해선, 이 숫자는 score-board를 통해 계산됩니다. branch nodes에 대해선, minimax 알고리즘에 기반하여 이 숫자는 계산됩니다.

 게임 트리의 모든 위치는 MAX 노드나 MIN 노드로 표시된 moves의 선택을 허용합니다. 이 그림이 분석하는 것은 플레이어 A를 위한 최선의 move를 찾는것에 기반하였기에 플레이어 A를 위한 선택이 허용된 모든 장소는 MAX로 표시되었습니다. 플레이어 B를 위한 선택이 허용된 모든 장소는 MIN으로 표시되었습니다. 이 그림에서 나온것 처럼, 이 게임은 매우 냉정하며, 플레이어 B가 실제 moves의 선택권을 가진 위치는 하나 밖에 없습니다. 다른 말로 하자면, 게임 트리에서 오직 하나의 MIN 노드가 존제합니다

 좌에서 우로 동작하는 minimax 알고리즘은, depth를 우선시하여, 모든 길을 탐험한것을 따라 leaves까지 살펴travel봅니다. 이를 depth-first 탐색이라 부릅니다. (*ai-level*이 매우 높게 설정되었고, 어떠한 trimming도 발생하지 않다고 가정하였습니다). 그런 다음 하나 이상의 가지를 지닌 노드에 대해 최대나 최소 score를 선택합니다.

 이를 수행하면, 이 그림에 있는 처음 MIN 노드의 (좌측) 가지는 score 8로 끝납니다. 이제 AI 엔진이 우측 가지로 파고든다면, 8보다 적게 남아있는 score를 찾는 것에만 신경을 쓸 것입니다. 8보다 같거나 큰 숫자는 결국 8이 될 것이며, 이와 같이 큰 숫자는 최종 계산 결과에 아무런 영향도 미치지 않을 것입니다.

 AI가 (그림에서 별표로 표시된) 우측 가지에 있는 노드찾으면, 우측 가지의 나머지는 영향을 미치지 않으며 계산에서 제거할 수 있다는 것을 알게됩니다. 이는 Minimax 알고리즘이 그림에서 점선으로 표시된 나무에 있는 가지를 살펴볼 필요가 없다는 것을 의미합니다

 이는 alpha-beta 가지치기가 행하는 것을 보여주는 간단한 예제입니다. 이 그림에서 보여진 게임 트리에선, 가지칠 수 있는 모든 노드 숫자가 적기에, 이 가지치기는 그다지 대단치 않은 절약saving만을 야기합니다. 그러나, 큰 게임 트리에서, alpha-beta 가지치기된 이 절약은 일반적으로 게임 트리에서 다수의 노드를 구성하는 어마어마한 것입니다.

 저희는 단순함을 유지하며 게임에서 alpha-beta 가지치기 구현하는 방식에 있어 자유로움을 지녔습니다. 우선, alpha-beta 가지치기 알고리즘은 보통 일반적으로 alpha와 beta라는 두 변수를 취합니다. 상한과 하한값 사이에 있는 alpha와 beta를 바꿈으로써 MAX노드와 MIN 노드를 동시에 다루는 코드를 작성할 수 있기 때문입니다. 대신에 저희 예제에선, 가장 크고 작은 값을 나타내기 위해 변수 upper-limit과 lower-limit를 사용하였습니다. MAX와 MIN의 경우를 다루는 비용으로 반복적으로-살펴보게되는 코드가 될 것입니다. 그러나, alpha-beta 가지치기란 용어를 upper-limit과 lower-limit이라 생각하면 코드가 이해하기 쉬워집니다.

 또다른 절충안은 minimax 코드로부터 가지치는 코드를 분리시키지 않는 것입니다. trimmming 코드를 살펴보면, AI코드의 나머지로부터 trimming의 행동 분리시킨 limit-tree-depth란 독립적인 함수를 작성했습니다. alpha-beta 가지치기 코드를 적절히 분리하기 위해, 게임트리를 pruned 버전으로 변형시킬 수 있는 함수를 만드는, 유사한 접근법을 이용할 수 있습니다. 그러나 이를 하는 것은, alpha-beta 가지치기 코드는 minimax 계산 중간에 접근해야 하기에 훨씬 어렵습니다. 더욱 진보된 AI 엔진을 위해선, 이는 좋은 idea가 될 것입니다. 저희의 간단한 엔진에선, alpha-beta 가지치기 검사를 minimax 함수 내부에 곧바로 넣을 것입니다.

 이제 시작해봅시다. 우선 두 새로운 변수로 get-rate 함수를 다시 작성해야 합니다. ab-get-ratings-max와 ab-get-ratings-min. get-rating 함수가 하나의-보드 배열로부터 다수의 move가 가능한것이 아닌 가장 최선의 score를 계산해야 한다는 것을 기억하시기 바랍니다. 그러나, 저희는 이제 일단 "가능한 좋은" move를 찾았다고 결정하면 move의 평가를 일찍 종료하기를 원합니다. 이 지점에 도달한 것을 결정하는 것은, 노드가 MAX move(현재 플레이어를 위한 move)인지 MIN move(적을 위한 move)인지에 달려있어 미묘하게 다릅니다.

 MAX 노드에 관한 version를 우선 살펴봅시다:
[source]

 이제 저희는 추가 upper-limit과 lower-limit 인자를 ab-get-rating-max로 넘겨줍니다. 실제로 이 함수는 주어진 지점에서 가능한 최대 rating을 찾는데에만 관심이 있기에 lower-limit 인자를 직접 확인하지는 않습니다. 그러나, 이는 이 값을 아마도 하한을 고려하는 것과 관련된 MIN 노드를 포함할지도 모르는 자식 가지로 넘깁니다.

 (곧 작성하게될, ab-rate-position을 호출하여) 트리의 다음 가지를 rate하면
, 결과를 x로 저장합니다. x가 upper-limit과 크거나 같다면, 결과가 우리가 희망했던 것만큼 좋다는 것을 알게 되며, 리스트의 마지막 값으로 최근 rating을 반환할 수 있습니다.

 x가 충분히 크지 않다면, 남아있는 가지를 계속 살펴봐야 합니다. 이전 lower-limit보다 크다면 x는 새로운 lower-limit이 될 것입니다.

 다음으로, ab-get-rating-min 함수를 살펴봅시다:
[source]

 상한과 하한이 뒤집혔다는 점을 제외하면 ab-get-ratings-min 함수는 본질적으로 ab-get-ratings-max 함수와 같습니다. 이 두 함수의 반복성에 기반하여, 여러분은 아마도, ab-get-rating-max와 ab-get-rating-min 함수가 하나의 함수로 결합하게 되는 것을 상상할 수 있을 것입니다. 이전에 언급하였듯이, 이 접근법에선 더욱 제레릭한 용어를 사용하여 MAX 노드나 MIN노드에 차이에 기반한 alpha와 beta를 사용한 것보다 upper-limit과 lower-limit이 낫습니다.

 다음으로, 단일 보드 배치를 rate하는 rate-position을 수정해야합니다:
[source]

 새로운 ab-rate-position에선, 게임 트리의 노드가 우리를 위한 move인지 적을 위한 move인지를 확인해야 합니다. 저희를 위한 move라면, 이는 MAX노드이며, ab-get-ratings-max로 보낼 것입니다. 이게 적의 턴이라면, 대신 ab-get-ratings-min으로 보냅니다. 그렇지 않다면, ab-rate-position은 이전 rate-position함수와 동일합니다.

 alpha-beta 가지치기 지원을 완성하기 위해, 함수 하나를 더 수정해야 합니다: minimax 계산을 시작하는 handle-computer 함수:
[source]

 첫번째 move가 가장 확실히 target 플레이어에 속해있으며, 따라서 MAX 노드이므로,
이 함수는 ab-get-ratings-max를 호출하여 minimax 계산을 시작합니다.

 이 함수를 호출하면, 시작 upper-limit과 lower-limit을 통과시켜야 합니다. minimax 탐색의 시작지점에 있기에, 이를 가능한 크고 작도록 설정합니다. 이상적으로, 저희는 양의 무한대와 음의 무한대로 설정하기 원합니다. 비록 많은 Lisp 환경이 이와 같은 개념을 지원하지만, 이는 ANSI Common Lisp 표준이 아닙니다. 그러나, 표준은 저희 목적에 완전히 부합하는 매우 큰 양수와 음수인 most-positive-fixnum과 most-negative-fixnum를 정의하였습니다. 따라서 이들을 ab-get-rating-max로 넣어 저희 한계를 설정합니다.

 AI 엔진에서 조금 더 효율성을 짜내길 원한다면, 대신 upper-limit과 lower-limit을 score-board 함수의 maximum과 minimum 값으로 설정할 수 있습니다. 이는 가지치기가 가능한 양을 미세하게 증가시켰습니다. 그러나, score-board 함수는 보드 크기에 기반한 다양한 score 범위를 반환할 것입니다. 그리고 보드 scoring을 최적화 하기로 결정하였다면, 다른 의존성을 지닙니다. 그러므로, minimax 계산의 시작에 대한 한계를 무한대에 가까이 설정하여 이에 관해 걱정할 필요가 없게된다면 가장 좋을 것입니다.

 AI 성능을 다시 향상시킨 마지막 보상으로, 보드의 크기를 5x5 게임 필드를 이용하여 늘려봅시다. 새로운 lazy, trimmed, pruned AI 알고리즘으로, 커다란 보드를 손쉽게(without a sweat) 다룰 수 있게 되었습니다:
[source]

NOTE
 이전 함수에 memoization을 썼다는 것을 기억하시기 바랍니다. 4x4 보드에서 이미 몇몇 게임을 했었다면, 특별한 함수인 neighbors 함수는 예전 보드 크기에 기반하여 결과를 리턴할 것입니다. Lisp를 재시작 없이 4x4 보드에서 플레이 할때만 잠재적으로 이슈가 될 것입니다. 이를 고치려면, 캐쉬된 결과를 지우기 위해 (파일 하단부에 있는 memoize된 revision을 포함하여) 단순히 REPL에서 dice_of_doom_v1.lisp에 있는 neightbors 함수의 정의를 다시하면 됩니다.

 여기 저희 게임이 있습니다:
[REPL]

 이 시점에서, REPL 게임 인터페이스는 이러한 커다란 게임 필드에 대해 매우 현실성이 없게 되었습니다. 다음에 이것을 다룰 것입니다.


What You’ve Learned
 이번장에선, 저희는 Dice of Doom 게임의 컴퓨터 플레이어가 더욱 더 정교해지도록 만들었습니다. 저희는 lazy 리스트를 이용하여 게임 트리를 구현했으며, AI 엔진에 의해 탐색되는 보드 위치의 수를 제한하는 몇몇 최적화 기술을 적용하였습니다. 이러한 과정속에서, 다음에 나오는 것을 배웠습니다:

z Lazy 프로그래밍은 매우 큰 데이터 구조 (심지어 무한한)를 다룰수 있도록 해주며 매우 효율적으로 처리하도록 해준다.
z lazy 매크로와 force함수를 지녔다면 이를 이용하여 lazy 리스트 라이브러리를 만드는 것을 포함하여 더욱 정교한 lazy 연산자를 이용할 수 있다.
z Heuristics은 창의적인 생각으로 코드의 성능을 향상시킬 수 있는 완벽하지 않은 알고리즘이다. 저희 예제에서, heuristic로 leaf 노드들을 score 하도록 바꾸었습니다.
z Dice of Doom을 lazy 트리를 이용하는 것으로 변환하면, AI의 moves를 고려할때 AI의 생각의 깊이를 제한하기 위해, 게임 트리를 우아하게 trim 할 수 있다.
z Alpha-beta 가지치기pruning는 AI에 의해 고려될 move에 대해 마지막 score와 마주치는 길을 가지지 않은 가지를 가지침으로 보다 더 성능을 향상시킨다.